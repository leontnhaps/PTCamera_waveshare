import cv2
import numpy as np
import sys
import os
from numpy.linalg import norm
from ultralytics import YOLO

# ---------------------------------------------------------
# [1] ê¸°ì¡´ ëª¨ë“ˆ ë¡œë“œ
# ---------------------------------------------------------
sys.path.append(os.path.join(os.path.dirname(__file__), 'Com'))

try:
    from yolo_utils import predict_with_tiling
    print("âœ… ê¸°ì¡´ ì•Œê³ ë¦¬ì¦˜(yolo_utils) ë¡œë“œ ì„±ê³µ!")
except ImportError:
    print("âŒ ì˜¤ë¥˜: Com/yolo_utils.pyë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    sys.exit()

# =========================================================
# [ì„¤ì •] í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ ë° ëª¨ë¸ ê²½ë¡œ
# =========================================================
MODEL_PATH = "yolov11m_diff.pt"

# ì´ë¯¸ì§€ ê²½ë¡œ

# IMG_PREV_ON = r"C:\Users\gmlwn\OneDrive\ë°”íƒ• í™”ë©´\ICon1í•™ë…„\OpticalWPT\ì¶”ê³„ ì´í›„ìë£Œ\Diff YOLO Test\captures_gui_20251201_004045\img_t-15_p-075_20251201_004206_138_led_on_ud.jpg"
# IMG_PREV_OFF = r"C:\Users\gmlwn\OneDrive\ë°”íƒ• í™”ë©´\ICon1í•™ë…„\OpticalWPT\ì¶”ê³„ ì´í›„ìë£Œ\Diff YOLO Test\captures_gui_20251201_004045\img_t-15_p-075_20251201_004206_588_led_off_ud.jpg"
# IMG_CURR_ON = r"C:\Users\gmlwn\OneDrive\ë°”íƒ• í™”ë©´\ICon1í•™ë…„\OpticalWPT\ì¶”ê³„ ì´í›„ìë£Œ\Diff YOLO Test\captures_gui_20251201_004045\img_t-15_p-090_20251201_004204_348_led_on_ud.jpg"
# IMG_CURR_OFF = rC:\Users\gmlwn\OneDrive\ë°”íƒ• í™”ë©´\ICon1í•™ë…„\OpticalWPT\ì¶”ê³„ ì´í›„ìë£Œ\Diff YOLO Test\captures_gui_20251201_004045\img_t-15_p-090_20251201_004204_803_led_off_ud.jpg


IMG_PREV_ON = r"C:\Users\gmlwn\OneDrive\ë°”íƒ• í™”ë©´\ICon1í•™ë…„\OpticalWPT\ì¶”ê³„ ì´í›„ìë£Œ\Diff YOLO Dataset\ì ¤ë¨¼ê±°4\img_t+15_p-135_20251128_220759_113_led_on_ud.jpg"
IMG_PREV_OFF = r"C:\Users\gmlwn\OneDrive\ë°”íƒ• í™”ë©´\ICon1í•™ë…„\OpticalWPT\ì¶”ê³„ ì´í›„ìë£Œ\Diff YOLO Dataset\ì ¤ë¨¼ê±°4\img_t+15_p-135_20251128_220759_817_led_off_ud.jpg"
IMG_CURR_ON = r"C:\Users\gmlwn\OneDrive\ë°”íƒ• í™”ë©´\ICon1í•™ë…„\OpticalWPT\ì¶”ê³„ ì´í›„ìë£Œ\Diff YOLO Dataset\ì ¤ë¨¼ê±°4\img_t+15_p-150_20251128_220756_809_led_on_ud.jpg"
IMG_CURR_OFF = r"C:\Users\gmlwn\OneDrive\ë°”íƒ• í™”ë©´\ICon1í•™ë…„\OpticalWPT\ì¶”ê³„ ì´í›„ìë£Œ\Diff YOLO Dataset\ì ¤ë¨¼ê±°4\img_t+15_p-150_20251128_220757_770_led_off_ud.jpg"

CONF_THRES = 0.50 
IOU_THRES = 0.45

# =========================================================
# í•µì‹¬ ë¡œì§ (íŠ¹ì§• ì¶”ì¶œ & ìœ ì‚¬ë„) - GRAYSCALE ë²„ì „
# =========================================================
def get_feature_vector(roi_bgr):
    """
    [ğŸ†• GRAYSCALE ë°©ì‹]
    ìƒ‰ìƒ(H) ëŒ€ì‹  ë°ê¸° íŒ¨í„´ë§Œìœ¼ë¡œ íŠ¹ì§• ì¶”ì¶œ!
    - ìƒ‰ìƒ ì •ë³´ ì œê±° â†’ ëª…ì•” êµ¬ì¡°ì— ì§‘ì¤‘
    - HSV 15x8=120ì°¨ì› â†’ Gray 32ì°¨ì›ìœ¼ë¡œ ë‹¨ìˆœí™”
    """
    if roi_bgr is None or roi_bgr.size == 0: return None
    
    # 1. Grayscale ë³€í™˜
    gray = cv2.cvtColor(roi_bgr, cv2.COLOR_BGR2GRAY)
    
    # 2. [ì˜µì…˜] ë§ˆìŠ¤í¬ ìƒì„± (ë„ˆë¬´ ì–´ë‘ìš´ í”½ì…€ ì œê±°)
    # V < 30 ì œê±° íš¨ê³¼ ìœ ì§€ (ë°°ê²½ ê·¸ë¦¼ì ë¬´ì‹œ)
    mask = cv2.inRange(gray, 30, 255)
    
    # 3. íˆìŠ¤í† ê·¸ë¨ ê³„ì‚° (1D, 32 bins)
    # 0~255 ë°ê¸° ë²”ìœ„ë¥¼ 32ê°œ êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆ”
    hist = cv2.calcHist([gray], [0], mask, [32], [0, 256])
    
    # 4. ì •ê·œí™” & ë²¡í„°í™”
    cv2.normalize(hist, hist, 0, 1, cv2.NORM_MINMAX)
    return hist.flatten()  # 32ì°¨ì› ë²¡í„°

def calc_cosine_similarity(vec_a, vec_b):
    if vec_a is None or vec_b is None: return 0.0
    dot = np.dot(vec_a, vec_b)
    n_a, n_b = norm(vec_a), norm(vec_b)
    if n_a == 0 or n_b == 0: return 0.0
    return dot / (n_a * n_b)

def process_step(model, img_on, img_off, step_name="Step"):
    print(f"\n--- Processing {step_name} ---")
    diff = cv2.absdiff(img_on, img_off)
    
    # YOLO ìˆ˜í–‰
    boxes, scores, classes = predict_with_tiling(
        model, diff, rows=2, cols=3, overlap=0.15, 
        conf=CONF_THRES, iou=IOU_THRES
    )
    print(f"   -> {len(boxes)}ê°œ ê°ì²´ ê²€ì¶œë¨.")
    
    objects = []
    H, W = img_on.shape[:2]
    
    # â˜… [ì„¤ì •] íŒ¨ë”© ë¹„ìœ¨
    PADDING_RATIO = 2.0 
    
    for i, (x, y, w, h) in enumerate(boxes):
        # 1. íŒ¨ë”© í¬ê¸° ê³„ì‚°
        pad_w = int(w * PADDING_RATIO)
        pad_h = int(h * PADDING_RATIO)
        
        # 2. ì¢Œí‘œ í™•ì¥
        x1 = max(0, int(x - pad_w))
        y1 = max(0, int(y - pad_h))
        x2 = min(W, int(x + w + pad_w))
        y2 = min(H, int(y + h + pad_h))
        
        # 3. ROI ì¶”ì¶œ (LED ON ì›ë³¸ì—ì„œ)
        roi = img_on[y1:y2, x1:x2]
        
        if roi.size == 0: continue

        vec = get_feature_vector(roi)
        
        objects.append({
            'id': i,
            'box': (x1, y1, x2-x1, y2-y1),
            'roi': roi,
            'vec': vec
        })
    return objects

# =========================================================
# â˜… ì‹œê°í™” í•¨ìˆ˜ë“¤
# =========================================================
def show_roi_grid(objects, window_name):
    """ê²€ì¶œëœ ëª¨ë“  ROIë¥¼ í•œ ì°½ì— ëª¨ì•„ì„œ ë³´ì—¬ì¤Œ"""
    if not objects: return

    display_h = 150
    images = []
    
    for obj in objects:
        roi = obj['roi']
        h, w = roi.shape[:2]
        if h == 0 or w == 0: continue
        
        # ë¹„ìœ¨ ìœ ì§€ ë¦¬ì‚¬ì´ì§•
        scale = display_h / h
        new_w = int(w * scale)
        resized_roi = cv2.resize(roi, (new_w, display_h))
        
        # í…Œë‘ë¦¬ ë° ID í…ìŠ¤íŠ¸ ì¶”ê°€
        vis = cv2.copyMakeBorder(resized_roi, 20, 2, 2, 2, cv2.BORDER_CONSTANT, value=(40, 40, 40))
        cv2.putText(vis, f"ID:{obj['id']}", (5, 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        images.append(vis)
    
    if images:
        grid_img = np.hstack(images)
        cv2.imshow(window_name, grid_img)

def show_matched_pairs(matches):
    """ë§¤ì¹­ëœ ìŒ(Prev <-> Curr)ì„ ìœ„ì•„ë˜ë¡œ ë‚˜ì—´í•´ì„œ ë³´ì—¬ì¤Œ"""
    if not matches:
        print("ë§¤ì¹­ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    display_h = 120
    pair_images = []

    for (p_obj, c_obj, sim) in matches:
        roi1 = p_obj['roi']
        roi2 = c_obj['roi']
        
        # ë†’ì´ ë§ì¶¤
        h1, w1 = roi1.shape[:2]
        scale1 = display_h / h1
        roi1_vis = cv2.resize(roi1, (int(w1 * scale1), display_h))
        
        h2, w2 = roi2.shape[:2]
        scale2 = display_h / h2
        roi2_vis = cv2.resize(roi2, (int(w2 * scale2), display_h))
        
        # ê°€ìš´ë° ì—°ê²° ì •ë³´ì°½
        info_w = 150
        info_panel = np.zeros((display_h, info_w, 3), dtype=np.uint8)
        
        color = (0, 255, 0)
        cv2.putText(info_panel, f"Sim: {sim:.2f}", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
        cv2.putText(info_panel, "-------->", (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        # í•©ì¹˜ê¸°
        pair_row = np.hstack((roi1_vis, info_panel, roi2_vis))
        pair_row = cv2.copyMakeBorder(pair_row, 5, 5, 5, 5, cv2.BORDER_CONSTANT, value=(20, 20, 20))
        
        cv2.putText(pair_row, f"Prev ID:{p_obj['id']}", (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
        cv2.putText(pair_row, f"Curr ID:{c_obj['id']}", (pair_row.shape[1] - 100, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
        
        pair_images.append(pair_row)
    
    # ì„¸ë¡œë¡œ ìŒ“ê¸°
    max_w = max([img.shape[1] for img in pair_images])
    
    final_stack = []
    for img in pair_images:
        h, w = img.shape[:2]
        if w < max_w:
            img = cv2.copyMakeBorder(img, 0, 0, 0, max_w - w, cv2.BORDER_CONSTANT, value=(0, 0, 0))
        final_stack.append(img)
        
    result_img = np.vstack(final_stack)
    cv2.imshow("Matched Pairs Result (GRAYSCALE)", result_img)

# =========================================================
# ë©”ì¸ ì‹¤í–‰
# =========================================================
def main():
    if not os.path.exists(MODEL_PATH):
        print("âŒ ëª¨ë¸ íŒŒì¼ ì—†ìŒ")
        return
    model = YOLO(MODEL_PATH)

    prev_on = cv2.imread(IMG_PREV_ON)
    prev_off = cv2.imread(IMG_PREV_OFF)
    curr_on = cv2.imread(IMG_CURR_ON)
    curr_off = cv2.imread(IMG_CURR_OFF)

    if prev_on is None or curr_on is None:
        print("âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨")
        return

    # 1. ì²˜ë¦¬
    prev_objs = process_step(model, prev_on, prev_off, "PREV (Step 1)")
    curr_objs = process_step(model, curr_on, curr_off, "CURR (Step 2)")

    if not prev_objs or not curr_objs:
        print("âŒ ê°ì²´ ê²€ì¶œ ì‹¤íŒ¨")
        return

    # 2. ROI í™•ì¸ì°½
    show_roi_grid(prev_objs, "Step 1: Prev ROIs (Grayscale)")
    show_roi_grid(curr_objs, "Step 2: Curr ROIs (Grayscale)")

    # 3. ë§¤ì¹­ ìˆ˜í–‰
    print("\n=== ğŸ¤ ë§¤ì¹­ ë¶„ì„ (Cosine Similarity - GRAYSCALE) ===")
    print(f"íŠ¹ì§• ë²¡í„° ì°¨ì›: 32 (ë°ê¸° íˆìŠ¤í† ê·¸ë¨ë§Œ ì‚¬ìš©)")
    matches = []
    
    for p_obj in prev_objs:
        p_id = p_obj['id']
        best_sim = -1.0
        best_match_idx = -1
        
        for c_idx, c_obj in enumerate(curr_objs):
            c_id = c_obj['id']
            sim = calc_cosine_similarity(p_obj['vec'], c_obj['vec'])
            print(f"   ğŸ‘‰ Prev[{p_id}] vs Curr[{c_id}] : Sim {sim:.4f}")
            if sim > best_sim:
                best_sim = sim
                best_match_idx = c_idx
        
        # ì„ê³„ê°’ 0.8
        if best_sim > 0.8:
            print(f"âœ… MATCH: Prev[{p_obj['id']}] <==> Curr[{best_match_idx}] (Sim: {best_sim:.4f})")
            matches.append((p_obj, curr_objs[best_match_idx], best_sim))
        else:
            print(f"âŒ NO MATCH for Prev[{p_obj['id']}] (Best Sim was {best_sim:.4f})")

    # 4. ë§¤ì¹­ ê²°ê³¼ ì‹œê°í™”
    if matches:
        show_matched_pairs(matches)
    else:
        print("âš ï¸ ì‹œê°í™”í•  ë§¤ì¹­ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

    print("\nğŸ“¸ ëª¨ë“  ì°½ì´ ë–´ìŠµë‹ˆë‹¤. ì•„ë¬´ í‚¤ë‚˜ ëˆ„ë¥´ë©´ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    print("\nğŸ”¬ [Grayscale ë°©ì‹ íŠ¹ì§•]")
    print("  - ìƒ‰ìƒ ì •ë³´ ì œê±° (H, S ë¬´ì‹œ)")
    print("  - ë°ê¸° íŒ¨í„´ë§Œ ì‚¬ìš© (32-bin histogram)")
    print("  - HSV 120ì°¨ì› â†’ Gray 32ì°¨ì› (75% ê°ì†Œ)")
    cv2.waitKey(0)
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
