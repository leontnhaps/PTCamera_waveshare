{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6361c06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy<2.0 in c:\\users\\gmlwn\\anaconda3\\envs\\ptcamera_wavehsare_gpu\\lib\\site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Jupyter 전용 -> 현재 커널(지금 콘다 env)에만 적용됩니다.\n",
    "%pip install \"numpy<2.0\" --upgrade\n",
    "# 권장 고정: %pip install numpy==1.26.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f15cdae8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01msubprocess\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# 버전 확인\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-m\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshow\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtorch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtorchvision\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# torchvision을 0.18.1(cu118)로 재설치\u001b[39;00m\n\u001b[0;32m      6\u001b[0m subprocess\u001b[38;5;241m.\u001b[39mcheck_call([sys\u001b[38;5;241m.\u001b[39mexecutable, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-m\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpip\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muninstall\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-y\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchvision\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\gmlwn\\anaconda3\\envs\\PTCamera_wavehsare_gpu\\lib\\subprocess.py:364\u001b[0m, in \u001b[0;36mcheck_call\u001b[1;34m(*popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_call\u001b[39m(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    355\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run command with arguments.  Wait for command to complete.  If\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;124;03m    the exit code was zero then return, otherwise raise\u001b[39;00m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;124;03m    CalledProcessError.  The CalledProcessError object will have the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;124;03m    check_call([\"ls\", \"-l\"])\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 364\u001b[0m     retcode \u001b[38;5;241m=\u001b[39m call(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retcode:\n\u001b[0;32m    366\u001b[0m         cmd \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\gmlwn\\anaconda3\\envs\\PTCamera_wavehsare_gpu\\lib\\subprocess.py:347\u001b[0m, in \u001b[0;36mcall\u001b[1;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 347\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:  \u001b[38;5;66;03m# Including KeyboardInterrupt, wait handled that.\u001b[39;00m\n\u001b[0;32m    349\u001b[0m         p\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[1;32mc:\\Users\\gmlwn\\anaconda3\\envs\\PTCamera_wavehsare_gpu\\lib\\subprocess.py:1209\u001b[0m, in \u001b[0;36mPopen.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1207\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1211\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[0;32m   1213\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[0;32m   1214\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\gmlwn\\anaconda3\\envs\\PTCamera_wavehsare_gpu\\lib\\subprocess.py:1506\u001b[0m, in \u001b[0;36mPopen._wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1503\u001b[0m     timeout_millis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1505\u001b[0m     \u001b[38;5;66;03m# API note: Returns immediately if timeout_millis == 0.\u001b[39;00m\n\u001b[1;32m-> 1506\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWaitForSingleObject\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mtimeout_millis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1508\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;241m==\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mWAIT_TIMEOUT:\n\u001b[0;32m   1509\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TimeoutExpired(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, timeout)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys, subprocess\n",
    "# 버전 확인\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"show\", \"torch\", \"torchvision\"])\n",
    "\n",
    "# torchvision을 0.18.1(cu118)로 재설치\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"torchvision\"])\n",
    "subprocess.check_call([\n",
    "    sys.executable, \"-m\", \"pip\", \"install\",\n",
    "    \"--index-url\", \"https://download.pytorch.org/whl/cu118\",\n",
    "    \"torchvision==0.18.1\"\n",
    "])\n",
    "\n",
    "# (선택) torchaudio도 맞추기 — torch 2.3.* ↔ torchaudio 2.3.*\n",
    "# 이미 정상이라면 생략 가능\n",
    "# subprocess.check_call([\n",
    "#     sys.executable, \"-m\", \"pip\", \"install\",\n",
    "#     \"--index-url\", \"https://download.pytorch.org/whl/cu118\",\n",
    "#     \"torchaudio==2.3.0\"\n",
    "# ])\n",
    "\n",
    "print(\">> 설치 완료. 커널을 재시작하고 학습 셀을 다시 실행하세요.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59468b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch      : 2.3.1+cu118\n",
      "torchvision: 0.18.1+cu118\n",
      "numpy: 1.26.4\n",
      "torch : 2.3.1+cu118\n",
      "tv    : 0.18.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "print(\"torch      :\", torch.__version__)      # 2.3.0 예상\n",
    "print(\"torchvision:\", torchvision.__version__) # 0.18.1 예상\n",
    "import numpy, torch, torchvision\n",
    "print(\"numpy:\", numpy.__version__)        # 1.26.x 기대\n",
    "print(\"torch :\", torch.__version__)\n",
    "print(\"tv    :\", torchvision.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92f33e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.14\n",
      "Torch : 2.3.1+cu118  CUDA build: 11.8\n",
      "CUDA avail: True\n",
      "GPU: NVIDIA GeForce RTX 4070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch, platform\n",
    "print(\"Python:\", platform.python_version())\n",
    "print(\"Torch :\", torch.__version__, \" CUDA build:\", torch.version.cuda)\n",
    "print(\"CUDA avail:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "480d85a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: Red_reflector_detector.v4-annotatae_7_ver.yolov8\\data.yaml\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "DATA_DIR = Path(r\"Red_reflector_detector.v4-annotatae_7_ver.yolov8\")  # <-- 본인 경로\n",
    "data_yaml = DATA_DIR / \"data.yaml\"\n",
    "assert data_yaml.exists(), f\"data.yaml 못 찾음: {data_yaml}\"\n",
    "print(\"Using:\", data_yaml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "449029f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  images=1369  labels=1369\n",
      "valid  images= 334  labels= 334\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "def count_pairs(split):\n",
    "    img = list((DATA_DIR/split/\"images\").glob(\"*.*\"))\n",
    "    lbl = list((DATA_DIR/split/\"labels\").glob(\"*.txt\"))\n",
    "    return len(img), len(lbl)\n",
    "\n",
    "for sp in [\"train\",\"valid\",\"test\"]:\n",
    "    p = DATA_DIR/sp\n",
    "    if p.exists():\n",
    "        ni, nl = count_pairs(sp)\n",
    "        print(f\"{sp:5s}  images={ni:4d}  labels={nl:4d}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2744523c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ data.yaml 패치 완료:\n",
      " train: train/images\n",
      "val: valid/images\n",
      "nc: 1\n",
      "names:\n",
      "- Sticker\n",
      "roboflow:\n",
      "  workspace: fso-vk47d\n",
      "  project: red_reflector_detector-tosx4\n",
      "  version: 3\n",
      "  license: CC BY 4.0\n",
      "  url: https://universe.roboflow.com/fso-vk47d/red_reflector_detector-tosx4/dataset/3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "DATA_DIR = Path(r\"Red_reflector_detector.v3-annotatae_3_ver.yolov8\")  # 네 데이터 폴더\n",
    "data_yaml = DATA_DIR / \"data.yaml\"\n",
    "\n",
    "with open(data_yaml, \"r\", encoding=\"utf-8\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "# 1) valid → val 매핑\n",
    "if \"val\" not in cfg and \"valid\" in cfg:\n",
    "    cfg[\"val\"] = cfg[\"valid\"]\n",
    "\n",
    "# 2) 상대경로 정리: ../train/images  →  train/images  (같은 폴더 기준)\n",
    "def fix(p):\n",
    "    if isinstance(p, str) and p.startswith(\"../\"):\n",
    "        return p[3:]\n",
    "    return p\n",
    "\n",
    "for key in [\"train\", \"val\", \"test\"]:\n",
    "    if key in cfg and cfg[key]:\n",
    "        cfg[key] = fix(cfg[key])\n",
    "\n",
    "# 3) test 폴더가 실제 없으면 yaml에서 제거(선택)\n",
    "def exists_dir(rel_path):\n",
    "    p = (DATA_DIR / rel_path).resolve()\n",
    "    return p.exists()\n",
    "\n",
    "if \"test\" in cfg and cfg[\"test\"] and not exists_dir(cfg[\"test\"]):\n",
    "    print(\"[INFO] test 이미지 폴더가 없어 data.yaml에서 test 항목을 제거합니다.\")\n",
    "    cfg.pop(\"test\", None)\n",
    "\n",
    "# 4) 저장\n",
    "with open(data_yaml, \"w\", encoding=\"utf-8\") as f:\n",
    "    yaml.safe_dump(cfg, f, sort_keys=False, allow_unicode=True)\n",
    "\n",
    "print(\"✅ data.yaml 패치 완료:\\n\", yaml.safe_dump(cfg, sort_keys=False, allow_unicode=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cdd5336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스 0 이외 라벨 수: 0\n",
      "[0~1] 범위 벗어난 bbox 수: 0\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(r\"Red_reflector_detector.v3-annotatae_3_ver.yolov8\")\n",
    "splits = []\n",
    "for sp in [\"train\",\"val\",\"valid\",\"test\"]:\n",
    "    p = DATA_DIR/sp/\"labels\"\n",
    "    if p.exists(): splits.append(p)\n",
    "\n",
    "bad_cls, bad_box = [], []\n",
    "for lbl_dir in splits:\n",
    "    for txt in lbl_dir.glob(\"*.txt\"):\n",
    "        with open(txt, \"r\") as f:\n",
    "            for ln, line in enumerate(f, 1):\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) != 5: continue\n",
    "                c = int(float(parts[0]))\n",
    "                if c != 0:\n",
    "                    bad_cls.append((txt, ln, c))\n",
    "                try:\n",
    "                    x, y, w, h = map(float, parts[1:])\n",
    "                    if not (0 <= x <= 1 and 0 <= y <= 1 and 0 < w <= 1 and 0 < h <= 1):\n",
    "                        bad_box.append((txt, ln, x, y, w, h))\n",
    "                except:\n",
    "                    bad_box.append((txt, ln, parts[1:]))\n",
    "\n",
    "print(f\"클래스 0 이외 라벨 수: {len(bad_cls)}\")\n",
    "print(f\"[0~1] 범위 벗어난 bbox 수: {len(bad_box)}\")\n",
    "if bad_cls[:3]: print(\"예시(최대 3개):\", bad_cls[:3])\n",
    "if bad_box[:3]: print(\"예시(최대 3개):\", bad_box[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8be76e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.202 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.201  Python-3.10.14 torch-2.3.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4070 Laptop GPU, 8188MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=-1, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=Red_reflector_detector.v3-annotatae_3_ver.yolov8\\data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=80, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8m.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train_y8m_ud4, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/detect, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\gmlwn\\OneDrive\\ \\ICon1\\\\PTCamera_waveshare\\dataset\\runs\\detect\\train_y8m_ud4, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3776275  ultralytics.nn.modules.head.Detect           [1, [192, 384, 576]]          \n",
      "Model summary: 169 layers, 25,856,899 parameters, 25,856,883 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 41.07.4 MB/s, size: 329.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\gmlwn\\OneDrive\\바탕 화면\\ICon1학년\\광통신\\PTCamera_waveshare\\dataset\\Red_reflector_detector.v3-annotatae_3_ver.yolov8\\train\\labels.cache... 491 images, 246 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 491/491 490.3Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640 at 60.0% CUDA memory utilization.\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (NVIDIA GeForce RTX 4070 Laptop GPU) 8.00G total, 0.38G reserved, 0.24G allocated, 7.38G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
      "    25856899       79.07         1.825         51.49         462.3        (1, 3, 640, 640)                    list\n",
      "    25856899       158.1         2.315         34.42         184.4        (2, 3, 640, 640)                    list\n",
      "    25856899       316.3         3.387         60.61         191.3        (4, 3, 640, 640)                    list\n",
      "    25856899       632.5         5.337         102.1         195.5        (8, 3, 640, 640)                    list\n",
      "    25856899        1265         8.433           170         270.9       (16, 3, 640, 640)                    list\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 5 for CUDA:0 4.46G/8.00G (56%) \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 49.614.2 MB/s, size: 354.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\gmlwn\\OneDrive\\바탕 화면\\ICon1학년\\광통신\\PTCamera_waveshare\\dataset\\Red_reflector_detector.v3-annotatae_3_ver.yolov8\\train\\labels.cache... 491 images, 246 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 491/491 490.2Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 36.88.4 MB/s, size: 333.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\gmlwn\\OneDrive\\바탕 화면\\ICon1학년\\광통신\\PTCamera_waveshare\\dataset\\Red_reflector_detector.v3-annotatae_3_ver.yolov8\\valid\\labels.cache... 120 images, 65 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 120/120  0.0s\n",
      "Plotting labels to C:\\Users\\gmlwn\\OneDrive\\ \\ICon1\\\\PTCamera_waveshare\\dataset\\runs\\detect\\train_y8m_ud4\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005078125), 83 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\gmlwn\\OneDrive\\ \\ICon1\\\\PTCamera_waveshare\\dataset\\runs\\detect\\train_y8m_ud4\u001b[0m\n",
      "Starting training for 80 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/80      2.52G      2.027      5.331     0.8474          2        640: 100% ━━━━━━━━━━━━ 99/99 6.1it/s 16.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.6it/s 1.3s0.2s\n",
      "                   all        120        172     0.0835      0.372     0.0394     0.0131\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/80      2.52G      2.227      1.891     0.8616          1        640: 100% ━━━━━━━━━━━━ 99/99 6.8it/s 14.7s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 10.5it/s 1.1s.1s\n",
      "                   all        120        172   0.000486     0.0872   0.000238    0.00012\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/80      2.52G      2.199       1.47     0.8093          4        640: 100% ━━━━━━━━━━━━ 99/99 6.6it/s 15.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.7it/s 1.2s0.1s\n",
      "                   all        120        172      0.702      0.308      0.305       0.15\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/80      2.52G      2.206      1.196     0.8332          2        640: 100% ━━━━━━━━━━━━ 99/99 6.4it/s 15.5s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 8.5it/s 1.4s0.1s\n",
      "                   all        120        172      0.672      0.279      0.363      0.175\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/80      2.52G      2.422      1.267     0.8681          1        640: 100% ━━━━━━━━━━━━ 99/99 6.2it/s 16.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.2it/s 1.3s0.1s\n",
      "                   all        120        172      0.354      0.296      0.177     0.0645\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/80      2.52G      2.263      1.184     0.8418          0        640: 100% ━━━━━━━━━━━━ 99/99 6.7it/s 14.9s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 8.3it/s 1.4s0.1s\n",
      "                   all        120        172      0.542      0.262       0.27      0.115\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/80      2.52G      2.128      1.153     0.8492          0        640: 100% ━━━━━━━━━━━━ 99/99 6.4it/s 15.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.6it/s 1.2s0.1s\n",
      "                   all        120        172      0.742      0.488      0.544      0.264\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/80      2.52G      2.124     0.9874     0.8664          0        640: 100% ━━━━━━━━━━━━ 99/99 6.2it/s 16.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 8.9it/s 1.4s0.1s\n",
      "                   all        120        172      0.665      0.243      0.305      0.147\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/80      2.52G      2.096      1.042     0.8171          0        640: 100% ━━━━━━━━━━━━ 99/99 6.1it/s 16.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 8.7it/s 1.4s0.1s\n",
      "                   all        120        172      0.743      0.503      0.553      0.265\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/80      2.52G      2.094      1.039     0.8364          0        640: 100% ━━━━━━━━━━━━ 99/99 6.2it/s 16.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 10.4it/s 1.2s.1s\n",
      "                   all        120        172      0.693      0.494      0.533      0.244\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/80      2.52G      1.983     0.9025     0.8362          0        640: 100% ━━━━━━━━━━━━ 99/99 6.8it/s 14.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 10.4it/s 1.2s.1s\n",
      "                   all        120        172      0.734      0.401      0.471      0.227\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/80      2.52G      1.951     0.9062     0.8044          0        640: 100% ━━━━━━━━━━━━ 99/99 5.9it/s 16.8s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 8.4it/s 1.4s0.1s\n",
      "                   all        120        172      0.723      0.529      0.576      0.278\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/80      2.52G      2.013     0.9295      0.855          0        640: 100% ━━━━━━━━━━━━ 99/99 6.9it/s 14.4s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 10.7it/s 1.1s.2s\n",
      "                   all        120        172      0.753      0.444      0.512      0.226\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/80      2.52G      1.973     0.8641     0.8092          0        640: 100% ━━━━━━━━━━━━ 99/99 6.9it/s 14.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 10.6it/s 1.1s.2s\n",
      "                   all        120        172      0.909      0.465      0.531      0.239\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/80      2.52G      1.758      0.863     0.7719          2        640: 100% ━━━━━━━━━━━━ 99/99 7.0it/s 14.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 10.6it/s 1.1s.2s\n",
      "                   all        120        172      0.791      0.471      0.582      0.316\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/80      2.52G      1.711     0.8644     0.7869          4        640: 100% ━━━━━━━━━━━━ 99/99 7.0it/s 14.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 10.7it/s 1.1s.2s\n",
      "                   all        120        172      0.779      0.491      0.594      0.332\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/80      2.52G       1.77     0.8873     0.7698          4        640: 100% ━━━━━━━━━━━━ 99/99 7.0it/s 14.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 10.7it/s 1.1s.2s\n",
      "                   all        120        172      0.791      0.535      0.602      0.301\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/80      2.52G      1.599     0.7245     0.7341          1        640: 100% ━━━━━━━━━━━━ 99/99 7.0it/s 14.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 10.3it/s 1.2s.1s\n",
      "                   all        120        172      0.845       0.54      0.626      0.311\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/80      2.52G      1.639     0.7228     0.7233          0        640: 100% ━━━━━━━━━━━━ 99/99 7.0it/s 14.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 10.7it/s 1.1s.2s\n",
      "                   all        120        172      0.818      0.506      0.631       0.37\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/80      2.52G      1.792     0.9083     0.8149          2        640: 100% ━━━━━━━━━━━━ 99/99 7.0it/s 14.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 10.5it/s 1.1s.2s\n",
      "                   all        120        172      0.755      0.517      0.562      0.301\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/80      2.52G      1.649     0.8232     0.7401          0        640: 100% ━━━━━━━━━━━━ 99/99 7.0it/s 14.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 10.1it/s 1.2s.1s\n",
      "                   all        120        172      0.816      0.477      0.577      0.299\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/80      2.52G      1.836     0.9932     0.8027          0        640: 100% ━━━━━━━━━━━━ 99/99 7.0it/s 14.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 10.9it/s 1.1s.2s\n",
      "                   all        120        172      0.858      0.456      0.616      0.346\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/80      2.52G      1.774     0.9533     0.7905          2        640: 100% ━━━━━━━━━━━━ 99/99 7.0it/s 14.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 10.4it/s 1.2s.1s\n",
      "                   all        120        172      0.799      0.459      0.551      0.302\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/80      2.52G      1.696     0.8502      0.829          2        640: 100% ━━━━━━━━━━━━ 99/99 6.9it/s 14.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 10.5it/s 1.1s.2s\n",
      "                   all        120        172      0.746      0.506      0.589      0.347\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/80      2.52G      1.698     0.6884     0.7995          2        640: 100% ━━━━━━━━━━━━ 99/99 6.9it/s 14.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 10.5it/s 1.1s.2s\n",
      "                   all        120        172      0.841      0.547      0.662      0.377\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/80      2.52G      1.401     0.6244     0.7703          0        640: 100% ━━━━━━━━━━━━ 99/99 6.9it/s 14.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 10.7it/s 1.1s.2s\n",
      "                   all        120        172      0.764      0.506       0.62      0.366\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/80      2.52G      1.457     0.6851     0.7281          0        640: 100% ━━━━━━━━━━━━ 99/99 6.9it/s 14.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.5it/s 1.3s0.1s\n",
      "                   all        120        172      0.756      0.521      0.633      0.366\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/80      2.52G       1.63     0.7207     0.7728          2        640: 100% ━━━━━━━━━━━━ 99/99 6.7it/s 14.8s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.7it/s 1.2s0.1s\n",
      "                   all        120        172      0.849      0.547      0.663      0.357\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/80      2.52G      1.701     0.7445     0.7914          4        640: 100% ━━━━━━━━━━━━ 99/99 6.7it/s 14.7s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.7it/s 1.2s0.1s\n",
      "                   all        120        172       0.79        0.5      0.607      0.351\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/80      2.52G      1.544      0.649      0.787          0        640: 100% ━━━━━━━━━━━━ 99/99 6.7it/s 14.8s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.8it/s 1.2s0.2s\n",
      "                   all        120        172      0.838       0.54      0.672      0.389\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      31/80      2.52G      1.557      0.677     0.7817          7        640: 100% ━━━━━━━━━━━━ 99/99 6.7it/s 14.9s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.6it/s 1.2s0.1s\n",
      "                   all        120        172      0.864      0.494      0.631      0.324\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      32/80      2.52G      1.508     0.6538      0.759          0        640: 100% ━━━━━━━━━━━━ 99/99 6.7it/s 14.8s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.8it/s 1.2s0.1s\n",
      "                   all        120        172      0.827      0.576      0.671      0.386\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      33/80      2.52G      1.484      0.646     0.7614          0        640: 100% ━━━━━━━━━━━━ 99/99 6.7it/s 14.8s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 10.2it/s 1.2s.1s\n",
      "                   all        120        172      0.885      0.558      0.683      0.391\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      34/80      2.52G       1.44     0.6504     0.7579          2        640: 100% ━━━━━━━━━━━━ 99/99 6.8it/s 14.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 10.2it/s 1.2s.2s\n",
      "                   all        120        172      0.887      0.593      0.696      0.375\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      35/80      2.52G      1.537     0.7288     0.8148          0        640: 100% ━━━━━━━━━━━━ 99/99 6.7it/s 14.9s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 10.0it/s 1.2s.1s\n",
      "                   all        120        172      0.815      0.552      0.644      0.358\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      36/80      2.52G      1.369     0.5949      0.703          2        640: 100% ━━━━━━━━━━━━ 99/99 6.7it/s 14.7s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.7it/s 1.2s0.1s\n",
      "                   all        120        172      0.884      0.558      0.653      0.408\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      37/80      2.52G       1.45     0.6312     0.8057          2        640: 100% ━━━━━━━━━━━━ 99/99 6.7it/s 14.7s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.6it/s 1.3s0.1s\n",
      "                   all        120        172      0.846      0.547      0.641      0.368\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      38/80      2.52G      1.484     0.6433     0.7701          2        640: 100% ━━━━━━━━━━━━ 99/99 6.6it/s 15.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.2it/s 1.3s0.1s\n",
      "                   all        120        172      0.793      0.536       0.66      0.394\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      39/80      2.52G      1.368     0.5732     0.7544          3        640: 100% ━━━━━━━━━━━━ 99/99 6.7it/s 14.8s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 10.1it/s 1.2s.2s\n",
      "                   all        120        172      0.912      0.545      0.683      0.392\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      40/80      2.52G      1.509     0.6957     0.7878          2        640: 100% ━━━━━━━━━━━━ 99/99 6.5it/s 15.2s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.8it/s 1.2s0.1s\n",
      "                   all        120        172      0.801       0.57      0.665      0.385\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      41/80      2.52G       1.42     0.5963     0.7232          2        640: 100% ━━━━━━━━━━━━ 99/99 6.6it/s 15.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.8it/s 1.2s0.1s\n",
      "                   all        120        172      0.844      0.581      0.696       0.42\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      42/80      2.52G      1.498     0.6168     0.7895          5        640: 100% ━━━━━━━━━━━━ 99/99 6.6it/s 14.9s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 10.3it/s 1.2s.2s\n",
      "                   all        120        172       0.85      0.581      0.711      0.429\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      43/80      2.52G      1.347     0.5951     0.7543          4        640: 100% ━━━━━━━━━━━━ 99/99 6.7it/s 14.8s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.2it/s 1.3s0.1s\n",
      "                   all        120        172      0.903      0.597      0.718      0.419\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      44/80      2.52G      1.345     0.5769     0.7562          2        640: 100% ━━━━━━━━━━━━ 99/99 6.7it/s 14.8s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.9it/s 1.2s0.1s\n",
      "                   all        120        172      0.833       0.61      0.698       0.42\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      45/80      2.52G      1.376     0.6185      0.741          4        640: 100% ━━━━━━━━━━━━ 99/99 6.6it/s 14.9s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.7it/s 1.2s0.1s\n",
      "                   all        120        172      0.905       0.61      0.741      0.455\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      46/80      2.52G      1.309     0.5672     0.7526          1        640: 100% ━━━━━━━━━━━━ 99/99 6.7it/s 14.9s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.4it/s 1.3s0.1s\n",
      "                   all        120        172      0.887      0.593      0.727       0.45\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      47/80      2.52G      1.311     0.5845     0.7593          0        640: 100% ━━━━━━━━━━━━ 99/99 6.7it/s 14.8s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 10.0it/s 1.2s.1s\n",
      "                   all        120        172      0.905      0.581      0.729      0.411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      48/80      2.52G       1.24     0.5015     0.7323          0        640: 100% ━━━━━━━━━━━━ 99/99 6.6it/s 14.9s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.7it/s 1.2s0.1s\n",
      "                   all        120        172      0.926      0.587      0.738      0.472\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      49/80      2.52G      1.198     0.5008      0.716          2        640: 100% ━━━━━━━━━━━━ 99/99 6.7it/s 14.8s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.7it/s 1.2s0.1s\n",
      "                   all        120        172      0.927       0.57      0.736      0.489\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      50/80      2.52G      1.162     0.5154      0.731          0        640: 100% ━━━━━━━━━━━━ 99/99 6.7it/s 14.8s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.5it/s 1.3s0.1s\n",
      "                   all        120        172      0.913      0.622      0.764      0.491\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      51/80      2.52G      1.284     0.5366     0.7233          0        640: 100% ━━━━━━━━━━━━ 99/99 6.7it/s 14.7s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.6it/s 1.3s0.1s\n",
      "                   all        120        172      0.869      0.616      0.739      0.485\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      52/80      2.52G      1.272     0.5251     0.7398          4        640: 100% ━━━━━━━━━━━━ 99/99 6.7it/s 14.8s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.5it/s 1.3s0.2s\n",
      "                   all        120        172      0.841      0.593      0.715      0.421\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      53/80      2.52G      1.225     0.4995     0.7449          5        640: 100% ━━━━━━━━━━━━ 99/99 6.7it/s 14.9s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 10.0it/s 1.2s.1s\n",
      "                   all        120        172      0.917      0.651      0.757      0.477\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      54/80      2.52G      1.213     0.5165     0.7548          2        640: 100% ━━━━━━━━━━━━ 99/99 6.6it/s 15.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.8it/s 1.2s0.1s\n",
      "                   all        120        172      0.928      0.616      0.778      0.499\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      55/80      2.52G      1.076     0.5099     0.7205          4        640: 100% ━━━━━━━━━━━━ 99/99 6.7it/s 14.8s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.4it/s 1.3s0.1s\n",
      "                   all        120        172      0.952       0.58       0.72      0.472\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      56/80      2.52G      1.261      0.553     0.7251          2        640: 100% ━━━━━━━━━━━━ 99/99 6.6it/s 15.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.9it/s 1.2s0.1s\n",
      "                   all        120        172      0.894      0.587      0.722      0.464\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      57/80      2.52G      1.087     0.4664     0.7293          4        640: 100% ━━━━━━━━━━━━ 99/99 6.6it/s 15.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.9it/s 1.2s0.1s\n",
      "                   all        120        172      0.833      0.605      0.736      0.491\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      58/80      2.52G       1.14     0.4947     0.7236          4        640: 100% ━━━━━━━━━━━━ 99/99 6.7it/s 14.7s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.8it/s 1.2s0.1s\n",
      "                   all        120        172       0.89      0.616      0.767      0.513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      59/80      2.52G      1.108     0.4793     0.7163          0        640: 100% ━━━━━━━━━━━━ 99/99 6.6it/s 15.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.2it/s 1.3s0.1s\n",
      "                   all        120        172      0.847       0.61      0.765      0.498\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      60/80      2.52G      1.104     0.4777     0.7499          0        640: 100% ━━━━━━━━━━━━ 99/99 6.7it/s 14.8s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.5it/s 1.3s0.1s\n",
      "                   all        120        172      0.916      0.645      0.785      0.518\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      61/80      2.52G      1.124     0.4559     0.7397          5        640: 100% ━━━━━━━━━━━━ 99/99 6.7it/s 14.8s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.7it/s 1.2s0.1s\n",
      "                   all        120        172      0.906      0.614      0.753      0.475\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      62/80      2.52G      1.023     0.4302     0.6945          2        640: 100% ━━━━━━━━━━━━ 99/99 6.7it/s 14.7s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 10.1it/s 1.2s.2s\n",
      "                   all        120        172      0.893      0.628      0.766      0.521\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      63/80      2.52G      1.038     0.4333     0.6829          0        640: 100% ━━━━━━━━━━━━ 99/99 6.7it/s 14.7s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.5it/s 1.3s0.1s\n",
      "                   all        120        172      0.884      0.616      0.775       0.51\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      64/80      2.52G      1.186     0.5088     0.7745          0        640: 100% ━━━━━━━━━━━━ 99/99 6.6it/s 15.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.6it/s 1.2s0.1s\n",
      "                   all        120        172      0.899      0.663      0.793      0.523\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      65/80      2.52G      1.068       0.46     0.7154          2        640: 100% ━━━━━━━━━━━━ 99/99 6.7it/s 14.9s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 10.1it/s 1.2s.2s\n",
      "                   all        120        172      0.909      0.645      0.787      0.519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      66/80      2.52G      1.104     0.4471     0.7885          5        640: 100% ━━━━━━━━━━━━ 99/99 6.7it/s 14.8s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.7it/s 1.2s0.1s\n",
      "                   all        120        172      0.902      0.644      0.777      0.524\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      67/80      2.52G      1.114     0.4638     0.7344          1        640: 100% ━━━━━━━━━━━━ 99/99 6.6it/s 15.0s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 10.0it/s 1.2s.1s\n",
      "                   all        120        172      0.897      0.622      0.766      0.523\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      68/80      2.52G      1.091     0.4477     0.7779          0        640: 100% ━━━━━━━━━━━━ 99/99 6.5it/s 15.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 8.9it/s 1.3s0.1s\n",
      "                   all        120        172      0.901      0.637      0.782      0.523\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      69/80      2.52G      1.105     0.4646     0.7338          2        640: 100% ━━━━━━━━━━━━ 99/99 6.5it/s 15.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.7it/s 1.2s0.1s\n",
      "                   all        120        172      0.915      0.645      0.801      0.538\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      70/80      2.52G      1.007     0.4269     0.7199          0        640: 100% ━━━━━━━━━━━━ 99/99 6.6it/s 14.9s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.9it/s 1.2s0.1s\n",
      "                   all        120        172      0.926      0.655      0.803      0.535\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      71/80      2.52G     0.9645     0.4044     0.6706          0        640: 100% ━━━━━━━━━━━━ 99/99 6.1it/s 16.2s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 10.1it/s 1.2s.2s\n",
      "                   all        120        172      0.916      0.657      0.806      0.534\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      72/80      2.52G     0.9787     0.4068     0.6656          0        640: 100% ━━━━━━━━━━━━ 99/99 6.8it/s 14.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 10.5it/s 1.1s.2s\n",
      "                   all        120        172       0.91      0.646      0.793      0.532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      73/80      2.52G     0.8486     0.3772      0.627          2        640: 100% ━━━━━━━━━━━━ 99/99 6.8it/s 14.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.7it/s 1.2s0.1s\n",
      "                   all        120        172      0.922      0.651      0.791       0.53\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      74/80      2.52G     0.9667      0.396     0.6441          2        640: 100% ━━━━━━━━━━━━ 99/99 6.8it/s 14.7s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 10.0it/s 1.2s.2s\n",
      "                   all        120        172       0.91       0.65      0.799      0.536\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      75/80      2.52G     0.8913     0.3962     0.6762          0        640: 100% ━━━━━━━━━━━━ 99/99 6.8it/s 14.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.9it/s 1.2s0.1s\n",
      "                   all        120        172      0.902      0.642      0.786      0.537\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      76/80      2.52G     0.9333     0.3903     0.6685          2        640: 100% ━━━━━━━━━━━━ 99/99 6.8it/s 14.6s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.8it/s 1.2s0.1s\n",
      "                   all        120        172      0.904      0.655        0.8      0.542\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      77/80      2.52G     0.9048     0.3718     0.6729          0        640: 100% ━━━━━━━━━━━━ 99/99 6.7it/s 14.7s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.5it/s 1.3s0.1s\n",
      "                   all        120        172      0.929      0.657      0.806       0.54\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      78/80      2.52G     0.9357     0.3632     0.6718          2        640: 100% ━━━━━━━━━━━━ 99/99 6.8it/s 14.7s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 10.1it/s 1.2s.2s\n",
      "                   all        120        172      0.919      0.651      0.807      0.545\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      79/80      2.52G     0.9334     0.3988     0.6651          2        640: 100% ━━━━━━━━━━━━ 99/99 6.8it/s 14.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.7it/s 1.2s0.1s\n",
      "                   all        120        172      0.924      0.651      0.802      0.545\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      80/80      2.52G     0.9301      0.365     0.6954          2        640: 100% ━━━━━━━━━━━━ 99/99 6.7it/s 14.8s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 9.7it/s 1.2s0.1s\n",
      "                   all        120        172      0.899       0.67      0.808      0.551\n",
      "\n",
      "80 epochs completed in 0.380 hours.\n",
      "Optimizer stripped from C:\\Users\\gmlwn\\OneDrive\\ \\ICon1\\\\PTCamera_waveshare\\dataset\\runs\\detect\\train_y8m_ud4\\weights\\last.pt, 52.0MB\n",
      "Optimizer stripped from C:\\Users\\gmlwn\\OneDrive\\ \\ICon1\\\\PTCamera_waveshare\\dataset\\runs\\detect\\train_y8m_ud4\\weights\\best.pt, 52.0MB\n",
      "\n",
      "Validating C:\\Users\\gmlwn\\OneDrive\\ \\ICon1\\\\PTCamera_waveshare\\dataset\\runs\\detect\\train_y8m_ud4\\weights\\best.pt...\n",
      "Ultralytics 8.3.201  Python-3.10.14 torch-2.3.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4070 Laptop GPU, 8188MiB)\n",
      "Model summary (fused): 92 layers, 25,840,339 parameters, 0 gradients, 78.7 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 8.4it/s 1.4s0.2s\n",
      "                   all        120        172      0.899       0.67      0.808      0.551\n",
      "Speed: 0.3ms preprocess, 6.8ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\gmlwn\\OneDrive\\ \\ICon1\\\\PTCamera_waveshare\\dataset\\runs\\detect\\train_y8m_ud4\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000001340507C220>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,\n",
       "            0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,\n",
       "            0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,\n",
       "            0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,\n",
       "            0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,\n",
       "            0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.98824,\n",
       "            0.98824,     0.98824,     0.98824,     0.98824,     0.98824,     0.97727,     0.97727,     0.97727,     0.97727,     0.97727,     0.97727,     0.97727,     0.97727,     0.97727,     0.97727,     0.97727,     0.97727,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,     0.96667,\n",
       "            0.95652,     0.95652,     0.95652,     0.95652,     0.95652,     0.95652,     0.94949,     0.94949,     0.94949,     0.94949,     0.94949,     0.94949,     0.94949,     0.94949,     0.94949,     0.94949,     0.94949,     0.94949,     0.94949,     0.94949,     0.94949,     0.94949,     0.94949,\n",
       "            0.94949,     0.94949,     0.94949,     0.94949,     0.94949,     0.94949,     0.94949,     0.94949,     0.94949,     0.94949,     0.94949,     0.94949,     0.94949,     0.94949,     0.94949,     0.94949,     0.94949,     0.94393,     0.94393,     0.94393,     0.94393,     0.94393,     0.94393,\n",
       "            0.94393,     0.94393,     0.94393,     0.94393,     0.94393,     0.94393,     0.94393,     0.94393,     0.94393,     0.94393,     0.94393,     0.94393,     0.94393,     0.94393,     0.94393,     0.94393,     0.94393,     0.94393,     0.94393,     0.94393,     0.94393,     0.94393,     0.94393,\n",
       "            0.94393,     0.94393,     0.94393,     0.94393,     0.94393,     0.94393,     0.94393,     0.94393,     0.94393,     0.94393,     0.94393,     0.94393,     0.93805,     0.93805,     0.93805,     0.93805,     0.93805,     0.93805,     0.93805,     0.93805,     0.93805,     0.93805,     0.93805,\n",
       "            0.93805,     0.93805,     0.93805,     0.93805,     0.93805,     0.93805,     0.93805,     0.93805,     0.93805,     0.93805,     0.93805,     0.93805,     0.93805,     0.93805,     0.93805,     0.93805,     0.93805,     0.93805,     0.92623,     0.92623,     0.92623,     0.92623,     0.92623,\n",
       "            0.92623,     0.92623,     0.92623,     0.92623,     0.92623,     0.92623,     0.92623,     0.92623,     0.92623,     0.92623,     0.92623,     0.92623,     0.92623,     0.92623,     0.92623,     0.92623,     0.92623,     0.92623,     0.92623,     0.92623,     0.92623,     0.92623,     0.92623,\n",
       "            0.92623,     0.92623,     0.92623,     0.92623,     0.92623,     0.92623,     0.92623,     0.92623,     0.92623,     0.92623,     0.92623,     0.92623,     0.92623,      0.9127,      0.9127,      0.9127,      0.9127,      0.9127,      0.9127,      0.9127,      0.9127,      0.9127,      0.9127,\n",
       "             0.9127,     0.89922,     0.89922,     0.89922,     0.89922,     0.89922,     0.89922,     0.86131,     0.86131,     0.86131,     0.86131,     0.86131,     0.86131,     0.86131,     0.86131,     0.86131,     0.86131,     0.86131,     0.86131,     0.85612,     0.85612,     0.85612,     0.85612,\n",
       "            0.85612,     0.85612,     0.83333,     0.83333,     0.83333,     0.83333,     0.83333,     0.81757,     0.81757,     0.81757,     0.81757,     0.81757,     0.81757,     0.79355,     0.79355,     0.79355,     0.79355,     0.79355,     0.79355,     0.79355,     0.79355,     0.79355,     0.79355,\n",
       "            0.79355,     0.79355,     0.79188,     0.78909,      0.7863,     0.78351,     0.78073,     0.77794,     0.77515,     0.77236,     0.76957,     0.76678,       0.764,     0.76121,     0.75842,     0.75563,     0.75284,     0.75005,     0.74727,     0.74448,     0.74169,      0.7389,     0.73611,\n",
       "            0.73332,     0.73054,     0.72775,     0.72496,     0.72217,     0.71938,     0.71659,     0.71381,     0.71102,     0.70823,     0.70544,     0.70265,     0.69986,     0.69708,     0.69429,      0.6915,     0.68871,     0.68592,     0.68313,     0.68035,     0.67756,     0.67477,     0.67198,\n",
       "            0.66919,      0.6664,     0.66362,     0.66083,     0.65804,     0.65525,     0.65246,     0.64968,     0.64689,      0.6441,     0.64131,     0.63852,     0.63573,     0.63295,     0.63016,     0.62737,     0.62458,     0.62179,       0.619,     0.61622,     0.61343,     0.61064,     0.60785,\n",
       "            0.60506,     0.60227,     0.59949,      0.5967,     0.59391,     0.59112,     0.58833,     0.58554,     0.58276,     0.57997,     0.57718,     0.57439,      0.5716,     0.56881,     0.56603,     0.56324,     0.56045,     0.55766,     0.55487,     0.55208,      0.5493,     0.54651,     0.54372,\n",
       "            0.54093,     0.53814,     0.53535,     0.53257,     0.52978,     0.52699,      0.5242,     0.52141,     0.51862,     0.51584,     0.51305,     0.51026,     0.50747,     0.50468,     0.50189,     0.49911,     0.49632,     0.49353,     0.49074,     0.48795,     0.48517,     0.48238,     0.47959,\n",
       "             0.4768,     0.47401,     0.47122,     0.46844,     0.46565,     0.46286,     0.46007,     0.45728,     0.45449,     0.45171,     0.44892,     0.44613,     0.44334,     0.44055,     0.43776,     0.43498,     0.43219,      0.4294,     0.42661,     0.42382,     0.42103,     0.41825,     0.41546,\n",
       "            0.41267,     0.40988,     0.40709,      0.4043,     0.40152,     0.39873,     0.39594,     0.39315,     0.39036,     0.38757,     0.38479,       0.382,     0.37921,     0.37642,     0.37363,     0.37084,     0.36806,     0.36527,     0.36248,     0.35969,      0.3569,     0.35411,     0.35133,\n",
       "            0.34854,     0.34575,     0.34296,     0.34017,     0.33738,      0.3346,     0.33181,     0.32902,     0.32623,     0.32344,     0.32066,     0.31787,     0.31508,     0.31229,      0.3095,     0.30671,     0.30393,     0.30114,     0.29835,     0.29556,     0.29277,     0.28998,      0.2872,\n",
       "            0.28441,     0.28162,     0.27883,     0.27604,     0.27325,     0.27047,     0.26768,     0.26489,      0.2621,     0.25931,     0.25652,     0.25374,     0.25095,     0.24816,     0.24537,     0.24258,     0.23979,     0.23701,     0.23422,     0.23143,     0.22864,     0.22585,     0.22306,\n",
       "            0.22028,     0.21749,      0.2147,     0.21191,     0.20912,     0.20633,     0.20355,     0.20076,     0.19797,     0.19518,     0.19239,      0.1896,     0.18682,     0.18403,     0.18124,     0.17845,     0.17566,     0.17287,     0.17009,      0.1673,     0.16451,     0.16172,     0.15893,\n",
       "            0.15615,     0.15336,     0.15057,     0.14778,     0.14499,      0.1422,     0.13942,     0.13663,     0.13384,     0.13105,     0.12826,     0.12547,     0.12269,      0.1199,     0.11711,     0.11432,     0.11153,     0.10874,     0.10596,     0.10317,     0.10038,    0.097591,    0.094802,\n",
       "           0.092014,    0.089226,    0.086437,    0.083649,    0.080861,    0.078073,    0.075284,    0.072496,    0.069708,    0.066919,    0.064131,    0.061343,    0.058554,    0.055766,    0.052978,    0.050189,    0.047401,    0.044613,    0.041825,    0.039036,    0.036248,     0.03346,    0.030671,\n",
       "           0.027883,    0.025095,    0.022306,    0.019518,     0.01673,    0.013942,    0.011153,   0.0083649,   0.0055766,   0.0027883,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.75229,     0.75229,     0.75501,     0.75781,     0.76299,     0.76327,     0.76022,     0.75626,     0.76071,     0.76366,     0.76428,     0.76491,     0.76554,     0.76682,     0.76835,     0.77063,     0.76983,     0.76884,     0.76784,     0.76684,      0.7672,     0.76785,      0.7685,\n",
       "            0.76915,     0.76973,     0.77029,     0.77085,     0.77141,     0.76959,      0.7643,     0.76369,     0.76391,     0.76412,     0.76433,     0.76455,     0.76476,     0.76498,     0.76519,      0.7654,     0.76562,     0.76583,     0.76604,     0.76627,     0.76649,     0.76672,     0.76695,\n",
       "            0.76717,      0.7674,     0.76763,     0.76785,     0.76808,     0.76831,     0.76853,     0.76855,     0.76787,     0.76719,     0.76651,     0.76583,     0.76514,     0.76444,      0.7635,     0.76256,     0.76161,     0.76067,     0.75966,     0.75862,     0.75758,     0.75653,     0.75425,\n",
       "            0.75161,     0.75121,      0.7508,      0.7504,     0.74999,     0.74959,     0.74918,     0.74878,     0.74837,     0.74797,     0.74756,     0.74732,     0.74717,     0.74703,     0.74689,     0.74674,      0.7466,     0.74645,     0.74631,     0.74617,     0.74602,     0.74588,     0.74573,\n",
       "            0.74559,     0.74545,      0.7453,     0.74516,     0.74501,     0.74487,     0.74473,     0.74458,     0.74444,     0.74429,     0.74415,       0.744,     0.74386,     0.74372,     0.74357,     0.74343,     0.74328,     0.74314,     0.74271,     0.74192,     0.74112,     0.74032,     0.73952,\n",
       "            0.73872,     0.73882,     0.73897,     0.73913,     0.73928,     0.73943,     0.73959,     0.73974,     0.73989,     0.74005,      0.7402,     0.74035,      0.7405,     0.74066,     0.74081,     0.74096,     0.74111,     0.74133,     0.74276,     0.74332,     0.74091,     0.73912,     0.73831,\n",
       "             0.7375,     0.73669,     0.73587,     0.73506,     0.73484,     0.73468,     0.73453,     0.73437,     0.73422,     0.73406,      0.7339,     0.73375,     0.73359,     0.73343,     0.73328,     0.73312,     0.73297,     0.73281,     0.73265,      0.7325,     0.73234,     0.73218,     0.73203,\n",
       "            0.73187,     0.73171,     0.73156,      0.7314,     0.73124,     0.73109,     0.73093,     0.73077,     0.73061,     0.72999,     0.72793,     0.72591,     0.72458,     0.72325,     0.72191,     0.72161,     0.72189,     0.72217,     0.72245,     0.72273,     0.72301,     0.72328,     0.72356,\n",
       "            0.72384,     0.72389,     0.72356,     0.72323,      0.7229,     0.72257,     0.72224,     0.72191,     0.72158,     0.72125,     0.72092,     0.72059,     0.72026,     0.71993,      0.7196,     0.71938,      0.7193,     0.71921,     0.71912,     0.71904,     0.71895,     0.71886,     0.71877,\n",
       "            0.71869,      0.7186,     0.71851,     0.71843,     0.71834,     0.71825,     0.71816,     0.71808,     0.71799,      0.7179,     0.71781,     0.71773,     0.71764,     0.71755,     0.71747,     0.71738,     0.71729,      0.7172,     0.71712,     0.71703,     0.71694,     0.71685,     0.71677,\n",
       "            0.71668,     0.71659,      0.7165,     0.71642,     0.71633,     0.71624,     0.71615,     0.71607,     0.71598,     0.71589,      0.7158,     0.71572,     0.71563,     0.71554,     0.71545,     0.71537,     0.71528,     0.71519,      0.7151,     0.71502,     0.71493,     0.71484,     0.71431,\n",
       "             0.7134,     0.71249,     0.71158,     0.71067,      0.7088,     0.70559,     0.70528,     0.70509,     0.70491,     0.70472,     0.70453,     0.70435,     0.70416,     0.70398,     0.70379,      0.7036,     0.70342,     0.70323,     0.70304,     0.70286,     0.70267,     0.70249,      0.7023,\n",
       "            0.70211,     0.70193,     0.70174,     0.70155,     0.70137,     0.70118,     0.70099,     0.70081,     0.70061,     0.70042,     0.70023,     0.70003,     0.69984,     0.69964,     0.69945,     0.69925,     0.69906,     0.69886,     0.69867,     0.69847,     0.69828,     0.69808,     0.69789,\n",
       "            0.69769,      0.6975,      0.6973,      0.6971,     0.69691,     0.69671,     0.69652,     0.69632,     0.69613,     0.69589,     0.69552,     0.69514,     0.69476,     0.69439,     0.69401,     0.69363,     0.69325,     0.69287,      0.6925,     0.69212,     0.69174,     0.69136,     0.69127,\n",
       "            0.69146,     0.69165,     0.69184,     0.69202,     0.69221,      0.6924,     0.69258,     0.69277,     0.69296,     0.69314,     0.69333,     0.69352,      0.6937,     0.69259,     0.69127,     0.68995,     0.68754,     0.68394,     0.68378,     0.68362,     0.68346,      0.6833,     0.68314,\n",
       "            0.68298,     0.68281,     0.68265,     0.68249,     0.68233,     0.68217,     0.68201,     0.68185,     0.68169,     0.68153,     0.68137,      0.6812,     0.68104,     0.68088,     0.68072,     0.68056,      0.6804,     0.68024,     0.68008,     0.67991,     0.67975,     0.67959,     0.67943,\n",
       "            0.67927,     0.67911,     0.67729,     0.67545,     0.67392,     0.67314,     0.67235,     0.67157,     0.67078,     0.66999,      0.6692,     0.66671,     0.66415,     0.66446,     0.66476,     0.66507,     0.66537,     0.66567,     0.66598,     0.66628,     0.66658,     0.66617,     0.66548,\n",
       "            0.66479,      0.6641,      0.6634,     0.66271,     0.66201,     0.66169,     0.66191,     0.66214,     0.66237,     0.66259,     0.66282,     0.66304,     0.66327,     0.66349,     0.66372,     0.66394,     0.66411,     0.66402,     0.66394,     0.66385,     0.66376,     0.66368,     0.66359,\n",
       "            0.66351,     0.66342,     0.66333,     0.66325,     0.66316,     0.66308,     0.66299,     0.66291,     0.66282,     0.66273,     0.66265,     0.66256,     0.66248,     0.66239,      0.6623,     0.66222,     0.66213,     0.66205,     0.66196,     0.66188,     0.66179,      0.6617,     0.66162,\n",
       "            0.66153,     0.66145,     0.66136,     0.66127,     0.66119,      0.6611,     0.66101,     0.66093,     0.66084,     0.66076,     0.66067,     0.66058,      0.6605,     0.66041,     0.66033,     0.66024,     0.66015,     0.66007,     0.65998,     0.65989,     0.65981,     0.65972,     0.65964,\n",
       "            0.65955,     0.65946,     0.65938,     0.65929,      0.6592,     0.65912,     0.65903,     0.65935,     0.65988,      0.6604,     0.66091,     0.66143,      0.6607,     0.65964,     0.65859,     0.65752,     0.65646,       0.656,     0.65559,     0.65518,     0.65477,     0.65436,     0.65395,\n",
       "            0.65354,     0.65313,     0.65271,      0.6523,     0.65189,     0.65148,     0.65121,     0.65139,     0.65158,     0.65177,     0.65195,     0.65214,     0.65232,     0.65251,     0.65269,     0.65288,     0.65306,     0.65325,     0.65343,     0.65362,     0.65356,     0.65331,     0.65307,\n",
       "            0.65282,     0.65258,     0.65233,     0.65209,     0.65185,      0.6516,     0.65136,     0.65111,     0.65087,     0.65062,     0.65038,     0.65013,     0.64988,     0.64964,     0.64939,     0.64915,      0.6489,     0.64866,     0.64842,     0.64826,      0.6481,     0.64793,     0.64777,\n",
       "            0.64761,     0.64745,     0.64729,     0.64713,     0.64696,      0.6468,     0.64664,     0.64648,     0.64632,     0.64615,     0.64599,     0.64583,     0.64567,     0.64551,     0.64534,     0.64518,     0.64502,     0.64486,     0.64469,     0.64453,     0.64437,     0.64421,     0.64404,\n",
       "            0.64388,     0.64372,     0.64356,     0.64339,     0.64323,     0.64288,     0.64227,     0.64166,     0.64106,     0.64045,     0.63984,     0.63923,     0.63862,     0.63801,      0.6374,     0.63679,     0.63618,     0.63556,     0.63495,     0.63434,     0.63372,     0.63311,     0.63249,\n",
       "            0.63231,     0.63219,     0.63207,     0.63195,     0.63182,      0.6317,     0.63158,     0.63146,     0.63134,     0.63122,      0.6311,     0.63098,     0.63086,     0.63074,     0.63062,      0.6305,     0.63038,     0.63026,     0.63013,     0.63001,     0.62989,     0.62977,     0.62965,\n",
       "            0.62953,     0.62941,     0.62929,     0.62917,     0.62905,     0.62892,      0.6288,     0.62868,     0.62856,     0.62844,     0.62832,      0.6282,     0.62808,     0.62796,     0.62783,     0.62771,     0.62759,     0.62747,     0.62735,     0.62723,     0.62711,     0.62699,      0.6256,\n",
       "             0.6242,      0.6228,      0.6215,     0.62134,     0.62118,     0.62102,     0.62087,     0.62071,     0.62055,     0.62039,     0.62023,     0.62007,     0.61991,     0.61975,     0.61959,     0.61944,     0.61928,     0.61912,     0.61896,      0.6188,     0.61864,     0.61848,     0.61832,\n",
       "            0.61816,       0.618,     0.61784,     0.61768,     0.61752,     0.61736,      0.6172,     0.61705,     0.61689,     0.61673,     0.61657,     0.61641,     0.61625,     0.61609,     0.61577,     0.61525,     0.61473,     0.61422,      0.6137,     0.61318,     0.61266,     0.61214,     0.61162,\n",
       "            0.61111,     0.61059,     0.61033,     0.61018,     0.61003,     0.60987,     0.60972,     0.60957,     0.60942,     0.60926,     0.60911,     0.60896,      0.6088,     0.60865,      0.6085,     0.60835,     0.60819,     0.60804,     0.60789,     0.60773,     0.60758,     0.60743,     0.60727,\n",
       "            0.60712,     0.60697,     0.60681,     0.60666,     0.60651,     0.60635,      0.6062,     0.60605,     0.60589,     0.60574,     0.60559,     0.60543,     0.60528,     0.60512,     0.60497,     0.60461,     0.60296,     0.60131,     0.59965,     0.59877,     0.59819,      0.5976,     0.59702,\n",
       "            0.59644,     0.59585,     0.59527,     0.59469,      0.5941,     0.59351,     0.59313,     0.59275,     0.59237,     0.59199,     0.59161,     0.59124,     0.59086,     0.59048,      0.5901,     0.58972,     0.58934,     0.58896,     0.58858,     0.58819,     0.58781,     0.58743,     0.58705,\n",
       "            0.58667,     0.58629,      0.5859,     0.58552,     0.58514,     0.58476,     0.58437,     0.58399,     0.58361,     0.58322,     0.58284,     0.58246,     0.58207,     0.58139,      0.5806,      0.5798,       0.579,      0.5782,      0.5774,     0.57661,     0.57599,     0.57565,      0.5753,\n",
       "            0.57496,     0.57462,     0.57427,     0.57393,     0.57358,     0.57324,      0.5729,     0.57255,     0.57221,     0.57186,     0.57151,     0.57117,     0.57082,     0.57048,     0.57003,      0.5694,     0.56876,     0.56812,     0.56748,     0.56684,      0.5662,     0.56556,     0.56491,\n",
       "            0.55226,     0.55167,     0.55108,     0.55048,     0.54989,      0.5493,      0.5487,     0.54811,     0.54751,     0.54692,     0.54632,     0.54585,      0.5454,     0.54495,     0.54451,     0.54406,     0.54361,     0.54316,     0.54271,     0.54226,     0.54181,     0.54136,     0.54091,\n",
       "            0.54046,     0.53987,     0.53861,     0.53734,     0.53608,      0.5348,     0.53371,     0.53303,     0.53236,     0.53169,     0.53102,     0.53035,     0.52967,       0.529,     0.52832,     0.52762,     0.52579,     0.52394,      0.5221,      0.5223,     0.52268,      0.5168,     0.51418,\n",
       "            0.51154,     0.50975,     0.50828,     0.50681,     0.50533,      0.5021,     0.49538,      0.4886,     0.47674,     0.47397,     0.47119,     0.46431,     0.46078,     0.45029,      0.4467,     0.44276,     0.42912,     0.42826,     0.42739,     0.42652,     0.42565,     0.42478,     0.42391,\n",
       "            0.42304,     0.42217,     0.40854,     0.40096,      0.3933,     0.37796,     0.37008,     0.35811,     0.35408,     0.34072,     0.33597,     0.33183,     0.31705,     0.30857,     0.28303,     0.27835,     0.27582,     0.27329,     0.27074,     0.26819,     0.26564,     0.26307,     0.25166,\n",
       "            0.24905,     0.24644,     0.24301,      0.2384,     0.21813,     0.20836,     0.20355,     0.17959,     0.17299,     0.16789,     0.16388,     0.16019,      0.1585,     0.15682,     0.15513,     0.15344,     0.15174,     0.13855,     0.13164,     0.12179,     0.11121,     0.10756,     0.10489,\n",
       "            0.10221,     0.09952,     0.09735,    0.095191,    0.093026,    0.090856,    0.088682,    0.086502,    0.084318,    0.082128,    0.079933,    0.064995,    0.053773,    0.039377,     0.03309,    0.031552,    0.030011,    0.028468,    0.026923,    0.025375,    0.023824,    0.022575,    0.021678,\n",
       "           0.020781,    0.019883,    0.018983,    0.018084,    0.017183,    0.016281,    0.015379,    0.014476,    0.013572,    0.012667,    0.011761,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.79355,     0.79355,      0.8226,     0.82929,     0.85042,     0.86007,     0.86041,      0.8594,     0.87233,     0.88011,     0.88178,     0.88345,     0.88512,     0.88857,     0.89268,     0.89885,     0.89905,     0.89885,     0.89866,     0.89847,     0.89991,     0.90171,      0.9035,\n",
       "            0.90529,     0.90688,     0.90845,     0.91002,     0.91158,     0.91232,     0.91142,     0.91179,     0.91241,     0.91302,     0.91363,     0.91424,     0.91486,     0.91547,     0.91608,     0.91669,      0.9173,     0.91792,     0.91853,     0.91917,     0.91983,     0.92048,     0.92114,\n",
       "            0.92179,     0.92245,      0.9231,     0.92376,     0.92441,     0.92507,     0.92572,     0.92621,     0.92611,     0.92601,     0.92591,     0.92581,     0.92571,     0.92561,     0.92547,     0.92533,      0.9252,     0.92506,     0.92491,     0.92476,      0.9246,     0.92445,     0.92411,\n",
       "            0.92371,     0.92365,     0.92359,     0.92353,     0.92347,     0.92341,     0.92335,     0.92328,     0.92322,     0.92316,      0.9231,     0.92306,     0.92304,     0.92302,       0.923,     0.92298,     0.92295,     0.92293,     0.92291,     0.92289,     0.92287,     0.92284,     0.92282,\n",
       "             0.9228,     0.92278,     0.92276,     0.92273,     0.92271,     0.92269,     0.92267,     0.92265,     0.92262,      0.9226,     0.92258,     0.92256,     0.92254,     0.92251,     0.92249,     0.92247,     0.92245,     0.92243,     0.92236,     0.92224,     0.92212,     0.92199,     0.92187,\n",
       "            0.92175,     0.92219,     0.92267,     0.92315,     0.92363,      0.9241,     0.92458,     0.92506,     0.92554,     0.92602,      0.9265,     0.92698,     0.92746,     0.92793,     0.92841,     0.92889,     0.92937,     0.93006,     0.93456,     0.93799,     0.93768,     0.93746,     0.93736,\n",
       "            0.93725,     0.93715,     0.93705,     0.93695,     0.93692,      0.9369,     0.93688,     0.93686,     0.93684,     0.93682,      0.9368,     0.93678,     0.93676,     0.93674,     0.93672,      0.9367,     0.93668,     0.93666,     0.93664,     0.93662,      0.9366,     0.93658,     0.93656,\n",
       "            0.93654,     0.93652,      0.9365,     0.93648,     0.93646,     0.93644,     0.93642,      0.9364,     0.93638,      0.9363,     0.93603,     0.93577,      0.9356,     0.93542,     0.93525,     0.93579,     0.93673,     0.93767,     0.93862,     0.93956,      0.9405,     0.94145,     0.94239,\n",
       "            0.94333,     0.94391,     0.94387,     0.94384,      0.9438,     0.94376,     0.94372,     0.94368,     0.94364,     0.94361,     0.94357,     0.94353,     0.94349,     0.94345,     0.94342,     0.94339,     0.94338,     0.94337,     0.94336,     0.94335,     0.94334,     0.94333,     0.94332,\n",
       "            0.94331,      0.9433,     0.94329,     0.94328,     0.94327,     0.94326,     0.94325,     0.94324,     0.94323,     0.94322,     0.94321,      0.9432,     0.94319,     0.94318,     0.94317,     0.94316,     0.94315,     0.94314,     0.94313,     0.94312,     0.94311,      0.9431,     0.94309,\n",
       "            0.94308,     0.94307,     0.94306,     0.94305,     0.94303,     0.94302,     0.94301,       0.943,     0.94299,     0.94298,     0.94297,     0.94296,     0.94295,     0.94294,     0.94293,     0.94292,     0.94291,      0.9429,     0.94289,     0.94288,     0.94287,     0.94286,      0.9428,\n",
       "            0.94269,     0.94258,     0.94248,     0.94237,     0.94215,     0.94176,     0.94173,      0.9417,     0.94168,     0.94166,     0.94164,     0.94161,     0.94159,     0.94157,     0.94155,     0.94152,      0.9415,     0.94148,     0.94146,     0.94143,     0.94141,     0.94139,     0.94137,\n",
       "            0.94134,     0.94132,      0.9413,     0.94128,     0.94125,     0.94123,     0.94121,     0.94119,     0.94116,     0.94114,     0.94111,     0.94109,     0.94107,     0.94104,     0.94102,       0.941,     0.94097,     0.94095,     0.94092,      0.9409,     0.94088,     0.94085,     0.94083,\n",
       "             0.9408,     0.94078,     0.94076,     0.94073,     0.94071,     0.94068,     0.94066,     0.94064,     0.94061,     0.94058,     0.94054,     0.94049,     0.94044,      0.9404,     0.94035,      0.9403,     0.94026,     0.94021,     0.94016,     0.94012,     0.94007,     0.94002,     0.94036,\n",
       "            0.94106,     0.94175,     0.94245,     0.94314,     0.94384,     0.94453,     0.94523,     0.94592,     0.94662,     0.94731,     0.94801,      0.9487,      0.9494,     0.94937,     0.94923,     0.94909,     0.94883,     0.94845,     0.94843,     0.94841,     0.94839,     0.94837,     0.94836,\n",
       "            0.94834,     0.94832,      0.9483,     0.94829,     0.94827,     0.94825,     0.94823,     0.94822,      0.9482,     0.94818,     0.94816,     0.94815,     0.94813,     0.94811,     0.94809,     0.94808,     0.94806,     0.94804,     0.94802,       0.948,     0.94799,     0.94797,     0.94795,\n",
       "            0.94793,     0.94792,     0.94772,     0.94751,     0.94734,     0.94725,     0.94717,     0.94708,     0.94699,      0.9469,     0.94681,     0.94653,     0.94625,     0.94749,     0.94873,     0.94997,     0.95121,     0.95245,     0.95369,     0.95493,     0.95617,     0.95647,     0.95641,\n",
       "            0.95634,     0.95628,     0.95621,     0.95615,     0.95608,     0.95642,     0.95737,     0.95832,     0.95926,     0.96021,     0.96116,      0.9621,     0.96305,       0.964,     0.96494,     0.96589,     0.96667,     0.96666,     0.96665,     0.96665,     0.96664,     0.96663,     0.96663,\n",
       "            0.96662,     0.96662,     0.96661,      0.9666,      0.9666,     0.96659,     0.96658,     0.96658,     0.96657,     0.96656,     0.96656,     0.96655,     0.96655,     0.96654,     0.96653,     0.96653,     0.96652,     0.96651,     0.96651,      0.9665,      0.9665,     0.96649,     0.96648,\n",
       "            0.96648,     0.96647,     0.96646,     0.96646,     0.96645,     0.96645,     0.96644,     0.96643,     0.96643,     0.96642,     0.96641,     0.96641,      0.9664,     0.96639,     0.96639,     0.96638,     0.96638,     0.96637,     0.96636,     0.96636,     0.96635,     0.96634,     0.96634,\n",
       "            0.96633,     0.96633,     0.96632,     0.96631,     0.96631,      0.9663,     0.96629,      0.9678,     0.97005,      0.9723,     0.97455,      0.9768,     0.97723,     0.97718,     0.97712,     0.97707,     0.97702,     0.97699,     0.97697,     0.97695,     0.97693,     0.97691,     0.97689,\n",
       "            0.97687,     0.97684,     0.97682,      0.9768,     0.97678,     0.97676,     0.97694,     0.97778,     0.97862,     0.97946,      0.9803,     0.98115,     0.98199,     0.98283,     0.98367,     0.98451,     0.98535,     0.98619,     0.98703,     0.98788,     0.98823,     0.98823,     0.98822,\n",
       "            0.98821,     0.98821,      0.9882,     0.98819,     0.98819,     0.98818,     0.98817,     0.98817,     0.98816,     0.98815,     0.98815,     0.98814,     0.98813,     0.98813,     0.98812,     0.98811,     0.98811,      0.9881,     0.98809,     0.98809,     0.98809,     0.98808,     0.98808,\n",
       "            0.98807,     0.98807,     0.98806,     0.98806,     0.98806,     0.98805,     0.98805,     0.98804,     0.98804,     0.98803,     0.98803,     0.98802,     0.98802,     0.98802,     0.98801,     0.98801,       0.988,       0.988,     0.98799,     0.98799,     0.98799,     0.98798,     0.98798,\n",
       "            0.98797,     0.98797,     0.98796,     0.98796,     0.98795,     0.98794,     0.98793,     0.98791,     0.98789,     0.98788,     0.98786,     0.98784,     0.98783,     0.98781,     0.98779,     0.98778,     0.98776,     0.98774,     0.98773,     0.98771,     0.98769,     0.98767,     0.98766,\n",
       "            0.98765,     0.98765,     0.98764,     0.98764,     0.98764,     0.98763,     0.98763,     0.98763,     0.98762,     0.98762,     0.98762,     0.98761,     0.98761,     0.98761,      0.9876,      0.9876,      0.9876,     0.98759,     0.98759,     0.98759,     0.98758,     0.98758,     0.98758,\n",
       "            0.98757,     0.98757,     0.98757,     0.98756,     0.98756,     0.98756,     0.98755,     0.98755,     0.98754,     0.98754,     0.98754,     0.98753,     0.98753,     0.98753,     0.98752,     0.98752,     0.98752,     0.98751,     0.98751,     0.98751,      0.9875,      0.9875,     0.98746,\n",
       "            0.98742,     0.98738,     0.98734,     0.98734,     0.98733,     0.98733,     0.98732,     0.98732,     0.98731,     0.98731,      0.9873,      0.9873,     0.98729,     0.98729,     0.98729,     0.98728,     0.98728,     0.98727,     0.98727,     0.98726,     0.98726,     0.98725,     0.98725,\n",
       "            0.98724,     0.98724,     0.98723,     0.98723,     0.98722,     0.98722,     0.98721,     0.98721,     0.98721,      0.9872,      0.9872,     0.98719,     0.98719,     0.98718,     0.98717,     0.98716,     0.98714,     0.98713,     0.98711,     0.98709,     0.98708,     0.98706,     0.98705,\n",
       "            0.98703,     0.98702,     0.98701,       0.987,       0.987,       0.987,     0.98699,     0.98699,     0.98698,     0.98698,     0.98697,     0.98697,     0.98696,     0.98696,     0.98695,     0.98695,     0.98694,     0.98694,     0.98693,     0.98693,     0.98693,     0.98692,     0.98692,\n",
       "            0.98691,     0.98691,      0.9869,      0.9869,     0.98689,     0.98689,     0.98688,     0.98688,     0.98687,     0.98687,     0.98686,     0.98686,     0.98686,     0.98685,     0.98685,     0.98683,     0.98678,     0.98673,     0.98668,     0.98665,     0.98663,     0.98662,      0.9866,\n",
       "            0.98658,     0.98656,     0.98654,     0.98652,     0.98651,     0.98649,     0.98647,     0.98646,     0.98645,     0.98644,     0.98643,     0.98641,      0.9864,     0.98639,     0.98638,     0.98636,     0.98635,     0.98634,     0.98633,     0.98632,      0.9863,     0.98629,     0.98628,\n",
       "            0.98627,     0.98625,     0.98624,     0.98623,     0.98622,      0.9862,     0.98619,     0.98618,     0.98616,     0.98615,     0.98614,     0.98613,     0.98611,     0.98609,     0.98606,     0.98604,     0.98601,     0.98598,     0.98596,     0.98593,     0.98591,      0.9859,     0.98589,\n",
       "            0.98588,     0.98586,     0.98585,     0.98584,     0.98583,     0.98582,      0.9858,     0.98579,     0.98578,     0.98577,     0.98576,     0.98575,     0.98573,     0.98572,     0.98571,     0.98568,     0.98566,     0.98564,     0.98562,      0.9856,     0.98557,     0.98555,     0.98553,\n",
       "            0.98507,     0.98505,     0.98503,     0.98501,     0.98498,     0.98496,     0.98494,     0.98492,      0.9849,     0.98487,     0.98485,     0.98483,     0.98482,      0.9848,     0.98478,     0.98477,     0.98475,     0.98473,     0.98471,      0.9847,     0.98468,     0.98466,     0.98465,\n",
       "            0.98463,     0.98461,     0.98456,     0.98451,     0.98446,     0.98441,     0.98437,     0.98434,     0.98431,     0.98429,     0.98426,     0.98423,     0.98421,     0.98418,     0.98415,     0.98413,     0.98405,     0.98398,      0.9839,     0.99054,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.71512,     0.71512,     0.69767,     0.69767,     0.69186,     0.68605,     0.68092,     0.67522,     0.67442,     0.67442,     0.67442,     0.67442,     0.67442,     0.67442,     0.67442,     0.67442,     0.67309,     0.67168,     0.67027,     0.66885,      0.6686,      0.6686,      0.6686,\n",
       "             0.6686,      0.6686,      0.6686,      0.6686,      0.6686,     0.66547,     0.65808,     0.65698,     0.65698,     0.65698,     0.65698,     0.65698,     0.65698,     0.65698,     0.65698,     0.65698,     0.65698,     0.65698,     0.65698,     0.65698,     0.65698,     0.65698,     0.65698,\n",
       "            0.65698,     0.65698,     0.65698,     0.65698,     0.65698,     0.65698,     0.65698,     0.65676,     0.65582,     0.65487,     0.65393,     0.65299,     0.65204,     0.65107,     0.64978,     0.64848,     0.64718,     0.64588,     0.64451,     0.64309,     0.64167,     0.64024,     0.63714,\n",
       "            0.63357,     0.63302,     0.63248,     0.63193,     0.63139,     0.63084,      0.6303,     0.62975,     0.62921,     0.62866,     0.62812,     0.62779,      0.6276,      0.6274,     0.62721,     0.62702,     0.62683,     0.62663,     0.62644,     0.62625,     0.62606,     0.62586,     0.62567,\n",
       "            0.62548,     0.62528,     0.62509,      0.6249,     0.62471,     0.62451,     0.62432,     0.62413,     0.62394,     0.62374,     0.62355,     0.62336,     0.62317,     0.62297,     0.62278,     0.62259,      0.6224,      0.6222,     0.62164,     0.62058,     0.61952,     0.61846,      0.6174,\n",
       "            0.61634,     0.61628,     0.61628,     0.61628,     0.61628,     0.61628,     0.61628,     0.61628,     0.61628,     0.61628,     0.61628,     0.61628,     0.61628,     0.61628,     0.61628,     0.61628,     0.61628,     0.61628,     0.61628,     0.61557,     0.61239,     0.61005,     0.60899,\n",
       "            0.60793,     0.60687,     0.60581,     0.60475,     0.60447,     0.60426,     0.60406,     0.60386,     0.60366,     0.60345,     0.60325,     0.60305,     0.60284,     0.60264,     0.60244,     0.60224,     0.60203,     0.60183,     0.60163,     0.60142,     0.60122,     0.60102,     0.60082,\n",
       "            0.60061,     0.60041,     0.60021,         0.6,      0.5998,      0.5996,      0.5994,     0.59919,     0.59899,     0.59818,     0.59553,     0.59293,     0.59123,     0.58953,     0.58782,     0.58721,     0.58721,     0.58721,     0.58721,     0.58721,     0.58721,     0.58721,     0.58721,\n",
       "            0.58721,     0.58705,     0.58664,     0.58622,      0.5858,     0.58538,     0.58496,     0.58455,     0.58413,     0.58371,     0.58329,     0.58287,     0.58245,     0.58204,     0.58162,     0.58134,     0.58123,     0.58112,     0.58101,      0.5809,     0.58079,     0.58068,     0.58057,\n",
       "            0.58047,     0.58036,     0.58025,     0.58014,     0.58003,     0.57992,     0.57981,      0.5797,     0.57959,     0.57948,     0.57937,     0.57926,     0.57915,     0.57904,     0.57893,     0.57882,     0.57871,      0.5786,     0.57849,     0.57838,     0.57827,     0.57816,     0.57805,\n",
       "            0.57794,     0.57783,     0.57772,     0.57761,      0.5775,     0.57739,     0.57728,     0.57717,     0.57706,     0.57695,     0.57684,     0.57673,     0.57662,     0.57651,      0.5764,     0.57629,     0.57618,     0.57607,     0.57596,     0.57585,     0.57574,     0.57563,     0.57497,\n",
       "            0.57383,      0.5727,     0.57156,     0.57042,      0.5681,     0.56412,     0.56373,      0.5635,     0.56328,     0.56305,     0.56282,     0.56259,     0.56236,     0.56213,      0.5619,     0.56167,     0.56144,     0.56121,     0.56098,     0.56075,     0.56053,      0.5603,     0.56007,\n",
       "            0.55984,     0.55961,     0.55938,     0.55915,     0.55892,     0.55869,     0.55846,     0.55823,       0.558,     0.55776,     0.55752,     0.55728,     0.55704,     0.55681,     0.55657,     0.55633,     0.55609,     0.55585,     0.55561,     0.55538,     0.55514,      0.5549,     0.55466,\n",
       "            0.55442,     0.55418,     0.55395,     0.55371,     0.55347,     0.55323,     0.55299,     0.55275,     0.55252,     0.55223,     0.55177,     0.55132,     0.55086,      0.5504,     0.54994,     0.54948,     0.54902,     0.54857,     0.54811,     0.54765,     0.54719,     0.54673,     0.54651,\n",
       "            0.54651,     0.54651,     0.54651,     0.54651,     0.54651,     0.54651,     0.54651,     0.54651,     0.54651,     0.54651,     0.54651,     0.54651,     0.54651,     0.54514,     0.54355,     0.54196,     0.53908,     0.53479,      0.5346,     0.53441,     0.53422,     0.53403,     0.53384,\n",
       "            0.53365,     0.53346,     0.53327,     0.53308,     0.53289,      0.5327,     0.53251,     0.53231,     0.53212,     0.53193,     0.53174,     0.53155,     0.53136,     0.53117,     0.53098,     0.53079,      0.5306,     0.53041,     0.53022,     0.53003,     0.52984,     0.52964,     0.52945,\n",
       "            0.52926,     0.52907,     0.52694,     0.52477,     0.52298,     0.52206,     0.52115,     0.52023,     0.51931,     0.51839,     0.51748,     0.51458,     0.51163,     0.51163,     0.51163,     0.51163,     0.51163,     0.51163,     0.51163,     0.51163,     0.51163,     0.51106,     0.51026,\n",
       "            0.50947,     0.50867,     0.50788,     0.50709,     0.50629,     0.50581,     0.50581,     0.50581,     0.50581,     0.50581,     0.50581,     0.50581,     0.50581,     0.50581,     0.50581,     0.50581,      0.5058,      0.5057,      0.5056,      0.5055,     0.50541,     0.50531,     0.50521,\n",
       "            0.50511,     0.50501,     0.50492,     0.50482,     0.50472,     0.50462,     0.50453,     0.50443,     0.50433,     0.50423,     0.50414,     0.50404,     0.50394,     0.50384,     0.50374,     0.50365,     0.50355,     0.50345,     0.50335,     0.50326,     0.50316,     0.50306,     0.50296,\n",
       "            0.50287,     0.50277,     0.50267,     0.50257,     0.50247,     0.50238,     0.50228,     0.50218,     0.50208,     0.50199,     0.50189,     0.50179,     0.50169,      0.5016,      0.5015,      0.5014,      0.5013,      0.5012,     0.50111,     0.50101,     0.50091,     0.50081,     0.50072,\n",
       "            0.50062,     0.50052,     0.50042,     0.50033,     0.50023,     0.50013,     0.50003,         0.5,         0.5,         0.5,         0.5,         0.5,     0.49906,     0.49786,     0.49667,     0.49548,     0.49429,     0.49377,     0.49331,     0.49285,     0.49239,     0.49193,     0.49147,\n",
       "            0.49102,     0.49056,      0.4901,     0.48964,     0.48918,     0.48872,     0.48837,     0.48837,     0.48837,     0.48837,     0.48837,     0.48837,     0.48837,     0.48837,     0.48837,     0.48837,     0.48837,     0.48837,     0.48837,     0.48837,     0.48822,     0.48795,     0.48768,\n",
       "             0.4874,     0.48713,     0.48686,     0.48659,     0.48632,     0.48605,     0.48578,     0.48551,     0.48524,     0.48497,      0.4847,     0.48442,     0.48415,     0.48388,     0.48361,     0.48334,     0.48307,      0.4828,     0.48254,     0.48236,     0.48218,       0.482,     0.48183,\n",
       "            0.48165,     0.48147,     0.48129,     0.48112,     0.48094,     0.48076,     0.48058,      0.4804,     0.48023,     0.48005,     0.47987,     0.47969,     0.47951,     0.47934,     0.47916,     0.47898,      0.4788,     0.47862,     0.47845,     0.47827,     0.47809,     0.47791,     0.47774,\n",
       "            0.47756,     0.47738,      0.4772,     0.47702,     0.47685,     0.47646,      0.4758,     0.47514,     0.47447,     0.47381,     0.47315,     0.47249,     0.47183,     0.47116,      0.4705,     0.46984,     0.46918,     0.46851,     0.46785,     0.46719,     0.46653,     0.46587,      0.4652,\n",
       "              0.465,     0.46487,     0.46474,     0.46462,     0.46449,     0.46436,     0.46423,      0.4641,     0.46397,     0.46384,     0.46371,     0.46358,     0.46345,     0.46332,     0.46319,     0.46306,     0.46293,      0.4628,     0.46267,     0.46254,     0.46241,     0.46228,     0.46215,\n",
       "            0.46202,     0.46189,     0.46177,     0.46164,     0.46151,     0.46138,     0.46125,     0.46112,     0.46099,     0.46086,     0.46073,      0.4606,     0.46047,     0.46034,     0.46021,     0.46008,     0.45995,     0.45982,     0.45969,     0.45956,     0.45943,      0.4593,     0.45783,\n",
       "            0.45634,     0.45485,     0.45347,     0.45331,     0.45314,     0.45297,      0.4528,     0.45263,     0.45247,      0.4523,     0.45213,     0.45196,     0.45179,     0.45163,     0.45146,     0.45129,     0.45112,     0.45096,     0.45079,     0.45062,     0.45045,     0.45028,     0.45012,\n",
       "            0.44995,     0.44978,     0.44961,     0.44944,     0.44928,     0.44911,     0.44894,     0.44877,     0.44861,     0.44844,     0.44827,      0.4481,     0.44793,     0.44777,     0.44743,     0.44689,     0.44634,      0.4458,     0.44526,     0.44472,     0.44418,     0.44364,     0.44309,\n",
       "            0.44255,     0.44201,     0.44175,     0.44159,     0.44143,     0.44127,     0.44111,     0.44095,     0.44079,     0.44063,     0.44047,     0.44032,     0.44016,        0.44,     0.43984,     0.43968,     0.43952,     0.43936,      0.4392,     0.43904,     0.43888,     0.43873,     0.43857,\n",
       "            0.43841,     0.43825,     0.43809,     0.43793,     0.43777,     0.43761,     0.43745,      0.4373,     0.43714,     0.43698,     0.43682,     0.43666,      0.4365,     0.43634,     0.43618,     0.43581,     0.43411,      0.4324,      0.4307,      0.4298,      0.4292,     0.42861,     0.42801,\n",
       "            0.42742,     0.42682,     0.42623,     0.42563,     0.42503,     0.42444,     0.42405,     0.42366,     0.42328,     0.42289,     0.42251,     0.42212,     0.42174,     0.42135,     0.42097,     0.42059,      0.4202,     0.41982,     0.41943,     0.41905,     0.41866,     0.41828,     0.41789,\n",
       "            0.41751,     0.41713,     0.41674,     0.41636,     0.41597,     0.41559,      0.4152,     0.41482,     0.41443,     0.41405,     0.41367,     0.41328,      0.4129,     0.41221,     0.41142,     0.41062,     0.40983,     0.40904,     0.40824,     0.40745,     0.40684,      0.4065,     0.40616,\n",
       "            0.40582,     0.40548,     0.40513,     0.40479,     0.40445,     0.40411,     0.40377,     0.40343,     0.40309,     0.40275,     0.40241,     0.40207,     0.40173,     0.40139,     0.40095,     0.40032,      0.3997,     0.39907,     0.39844,     0.39782,     0.39719,     0.39656,     0.39593,\n",
       "            0.38368,     0.38311,     0.38255,     0.38198,     0.38141,     0.38084,     0.38028,     0.37971,     0.37914,     0.37857,     0.37801,     0.37756,     0.37713,      0.3767,     0.37628,     0.37585,     0.37543,       0.375,     0.37458,     0.37415,     0.37373,      0.3733,     0.37287,\n",
       "            0.37245,      0.3719,      0.3707,     0.36951,     0.36832,     0.36713,      0.3661,     0.36547,     0.36484,     0.36422,     0.36359,     0.36296,     0.36233,     0.36171,     0.36108,     0.36043,     0.35873,     0.35703,     0.35532,     0.35465,      0.3538,     0.34844,     0.34606,\n",
       "            0.34367,     0.34206,     0.34074,     0.33941,     0.33809,      0.3352,     0.32924,     0.32328,     0.31297,     0.31059,     0.30821,     0.30235,     0.29936,     0.29056,     0.28758,     0.28433,     0.27317,     0.27247,     0.27177,     0.27107,     0.27037,     0.26967,     0.26897,\n",
       "            0.26827,     0.26756,     0.25671,     0.25075,     0.24479,     0.23301,     0.22706,     0.21811,     0.21513,     0.20534,      0.2019,     0.19892,     0.18839,     0.18243,     0.16485,     0.16167,     0.15997,     0.15827,     0.15657,     0.15486,     0.15316,     0.15146,     0.14394,\n",
       "            0.14224,     0.14054,     0.13831,     0.13533,     0.12242,      0.1163,     0.11331,    0.098655,    0.094682,    0.091635,    0.089251,    0.087067,    0.086073,     0.08508,    0.084087,    0.083094,    0.082101,    0.074429,    0.070456,    0.064841,    0.058882,    0.056835,    0.055345,\n",
       "           0.053855,    0.052366,    0.051166,    0.049974,    0.048782,     0.04759,    0.046398,    0.045206,    0.044014,    0.042822,    0.041631,    0.033589,    0.027629,    0.020084,    0.016823,    0.016029,    0.015234,     0.01444,    0.013645,     0.01285,    0.012056,    0.011416,    0.010958,\n",
       "             0.0105,    0.010041,   0.0095827,   0.0091243,   0.0086659,   0.0082074,    0.007749,   0.0072906,   0.0068322,   0.0063738,   0.0059154,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: 0.5506999469531715\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([     0.5507])\n",
       "names: {0: 'Sticker'}\n",
       "nt_per_class: array([172], dtype=int64)\n",
       "nt_per_image: array([55], dtype=int64)\n",
       "results_dict: {'metrics/precision(B)': 0.8986625271912739, 'metrics/recall(B)': 0.6702663904214291, 'metrics/mAP50(B)': 0.8084044937125895, 'metrics/mAP50-95(B)': 0.5506999469531715, 'fitness': 0.5506999469531715}\n",
       "save_dir: WindowsPath('C:/Users/gmlwn/OneDrive/바탕 화면/ICon1학년/광통신/PTCamera_waveshare/dataset/runs/detect/train_y8m_ud4')\n",
       "speed: {'preprocess': 0.2676616666500801, 'inference': 6.818632500009396, 'loss': 0.0026258333415777693, 'postprocess': 1.2087916666738843}\n",
       "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(\"yolov8m.pt\")\n",
    "model.train(\n",
    "    data=str(data_yaml),\n",
    "    imgsz=640, epochs=80, batch=-1,\n",
    "    device=0, amp=True, workers=4, cos_lr=True,\n",
    "    patience=20, project=\"runs/detect\", name=\"train_y8m_ud\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PTCamera_wavehsare_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
